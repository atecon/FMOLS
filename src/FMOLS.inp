function matrix timepoly (int T[1::],
                          int maxpower[0::])
    /* Compute constant and (non-)linear trend. */

    strings clabels = defarray("intercept")
    matrix ret = ones(T, 1)

    if maxpower > 0
        scalar hT = floor(T / 2)
        scalar even = T % 2
        matrix trend = seq((1 - even - hT), hT)'
        ret ~= trend.^seq(1, maxpower)

        loop i=1..maxpower
            clabels = clabels + sprintf("trend_pow_%d", $i)
        endloop
    endif

    cnameset(ret, clabels)

    return ret
end function

function string msg_type_dgp_x (const string type)
    /* Map selected type to unique ID. */

    if type == "c"
        ret = " Constant"
    elif type == "ct"
        ret = " Constant and trend"
    elif type == "ctt"
        ret = " Constant, linear and quadratic trend"
    endif

    return ret
end function


function string msg_prewhiten (const bool do_prewhite)
    /* For printing only. */
    if do_prewhite
        return " Pre-Whitened"
    else
        return " Not Pre-Whitened"
    endif
end function


function void print_results (const bundle self, const bundle model)
    /* Print estimation results. */

    matrix b1m = model.bhat_coint ~ model.se_coint
    matrix b2m = model.bhat_deter ~ model.se_deter
    string names_xlist = self.names_xlist

    names_deterministics = msg_type_dgp_x(self.type_deterministic)
    names_deterministics = strsub(names_deterministics, ",", "")
    names_deterministics = tolower(strsub(names_deterministics, "and", ""))
    string msg_type_dgp_x = msg_type_dgp_x(self.type_dgp_x)
    string msg_whiten = msg_prewhiten(self.do_prewhite)
    string msg_kernel = sprintf(" %s", toupper(self.type_kernel))

    if self.bandwidth == -1
        msg_band = sprintf("(automatic) estimate: %5.3g\n", self.bandwidth_value)
    else
        msg_band = sprintf("preset at: %2.3g\n", self.bandwidth_value)
    endif

    print  "======================================================================"
    print "Fully Modified Least Squares Regression"
    printf "using observations %s-%s (T = %d)\n", obslabel(self.t1),\
        obslabel(self.t2), self.T
    printf "Dependent variable: %s\n", self.name_endogenous
    print  "_____________________________________________________________________"
    print  ""
    print  "  I(1) variables"
    modprint b1m names_xlist
    print ""
    print "Deterministic terms"
    modprint b2m names_deterministics

    printf "Assumed regressor deterministics:"
    print msg_type_dgp_x

    printf "Method of estimation of covariance parameters:"
    print msg_whiten

    printf "Kernel:"
    print msg_kernel

    printf "Bandwidth "
    print msg_band

    print  "======================================================================\n\n"
end function


function scalar get_kernel_id (const string name)
    /* Map kernel type to unique ID. */

    bundle map = _(\
                    quadratic = 1,\
                    parzen = 2,\
                    bartlett = 3\
                )

    return map[name]
end function


function scalar bwidth (const string type_kernel,
                        int T,
                        const matrix ae,
                        const matrix se,
                        const scalar ad)
    /* Compute bandwidth. */

    if get_kernel_id(type_kernel) == 1       # Quadratic Spectral
        scalar coeff_white = 4 * ( sumc((ae.*se./((1-ae).^4)).^2) ) / ad
        eband = 1.3221 * ( (coeff_white * T)^.2 )
    elif get_kernel_id(type_kernel) == 2     # Parzen
        scalar coeff_white = 4 * ( sumc((ae.*se./((1-ae).^4)).^2) ) / ad
        eband = 2.6614 * ( (coeff_white * T)^.2 )
    elif get_kernel_id(type_kernel) == 3     # Bartlett
        scalar coeff_white = 4 * ( sumc((ae.*se./(((1-ae).^3).*(1+ae))).^2) )' / ad
        eband = 1.1447 * ( (coeff_white * T)^(1/3) )
    else
        funcerr sprintf("Kernel type '%s' not known. Abort.", type_kernel)
    endif

    return eband
end function


function scalar compute_bandwidth (const matrix mat,
                                   const string type_kernel)
    /* Compute optimal bandwidth.
    return: scalar value of optimal bandwidth. */

    scalar T = rows(mat)

    matrix eb = mat[1:(T-1),]
    matrix ef = mat[2:T,]
    matrix ae = ( sumc(eb .* ef)./sumc(eb.^2) )'
    matrix ee = ef - eb .* ae'
    matrix se = sqrt( meanc(ee.^2) )'
    scalar ad = sumc( (se ./ ((1 - ae).^2)).^2 )'

    return bwidth(type_kernel, T, ae, se, ad)
end function



function matrix compute_kernel (int T[1::],
                                const string type_kernel,
                                scalar bandwidth)
    /* Compute kernel-based weights. */

    matrix jb = seq(1, (T-1)) ./ bandwidth

    if get_kernel_id(type_kernel) == 1   # Quadratic Spectral
        jband = jb * 1.2 * $pi
        matrix kernel_est = 3 * ((sin(jband)./jband - cos(jband))./(jband.^2))
    elif get_kernel_id(type_kernel) == 2     #  Parzen
        matrix kernel_est = (1 - (jb.^2)*6 + (jb.^3)*6).*(jb .<= 0.5)
        kernel_est = kernel_est + 2 * ((1-jb).^3) .* ((jb .<=1) && (jb .> 0.5))
    elif get_kernel_id(type_kernel) == 3     #  Bartlett
        matrix kernel_est = (1-jb).*(jb .<= 1)
    else
        funcerr sprintf("Kernel type '%s' is not known. Abort.", type_kernel)
    endif

    return vec(kernel_est)
end function


function bundle check_sample (const list L)
    /*  Check for missing values and return sample start and end observations.*/

    scalar Told = $nobs
    smpl L --contiguous
    scalar Tnew = $nobs

    scalar Tdiff = Told - Tnew
    if Tdiff && self.verbose
        printf "\nWarning: Dropped %d observations due to missing values.\n", Tdiff
        printf "\nInfo: Sample range: %s to %s.\n", obslabe($t1), obslabe($t2)
    endif

    return _(t1 = $t1, t2 = $t2)
end function


function void add_column_dimensions (const list xlist, bundle *self)
    /*  Determine column dimensions of matrices. */

    scalar self.cols_mx = nelem(xlist)
    scalar self.cols_mymx = 1 + self.cols_mx
end function


function matrix get_shortrun_innovations (const list xlist "in levels",
                                          const list deter "Deterministics")
    /* Compute short-term innovations: deviations of 1st-differences from deterministics. */

    list sdx = diff(xlist)
    smpl sdx --no-missing
    matrix u = mshape(NA, $nobs, 1)

    mols({sdx}, {deter}, &u)

    return u
end function


function series get_longrun_innovations (const series y "Endogenous in levels",
                                         const list xlist "levels + deterministics")
    /* Compute long-run coefficient vector and return residuals which are equivalent to deviations from long-run relationship. */

    smpl y xlist --no-missing

    catch ols y xlist --quiet
    errorif($error, "Level estimation failed. Abort.")

    return $uhat
end function


function matrix est_var_model (const matrix m,
                               const int max_lag[1::],
                               matrix *uhat)
    /* Estimate a VAR model by mols(). Return coefficient matrix. */

    scalar init = 1 + max_lag      # get rid of initial NAs
    scalar T = rows(m)
    matrix p = seq(1, max_lag)
    matrix m_lags = mlag(m, p, NA)[init:,]

    matrix bhat = mols( m[init:,], m_lags, &uhat )
    errorif($error, "Pre-whitening failed. Abort.")

    return bhat
end function


function bundle fmols_defaults (void)
    /*  set and return default values. */

    bundle B

    string B.type_deterministic = "c"
    string B.type_dgp_x = "c"
    string B.type_kernel = "quadratic"
    scalar B.do_prewhite = TRUE
    scalar B.prewhitening_lag = 1
    scalar B.bandwidth = -1
    scalar B.verbose = TRUE

    return B
end function


function scalar get_trend_powermax (const string type)
    /* Map deterministics to maximum degree (power) of trend variable. */

    bundle map = _(\
                        c = 0,\
                        ct = 1,\
                        ctt = 2\
                    )

    return map[type]
end function


function bundle FMOLS (const series ys,
                       const list xlist,
                       const bundle opts[null])
    /* Public function calling all necessary steps. */

    bundle self = fmols_defaults()

    if exists(opts)
        self = opts + self
    endif

    self.type_deterministic = tolower(self.type_deterministic)
    self.type_dgp_x = tolower(self.type_dgp_x)
    self.type_kernel = tolower(self.type_kernel)
    string self.name_endogenous = argname(ys)
    string self.names_xlist = varname(xlist)

    self = self + check_sample(deflist(ys, xlist))
    smpl self.t1 self.t2
    scalar self.T = $nobs
    add_column_dimensions(xlist, &self)

    list det_levels
    list det_dynamics
    matrix mtmp = timepoly($nobs,\
                           get_trend_powermax(self.type_deterministic))
    loop i=1..cols(mtmp)
        det_levels += genseries(sprintf("%s", cnameget(mtmp)[i]), mtmp[,i])
    endloop

    # one obs. lost due to differencing for changes in levels
    smpl (self.t1+1) ;
    matrix mtmp = timepoly($nobs, get_trend_powermax(self.type_dgp_x))
    loop i=1..cols(mtmp)
        det_dynamics += genseries(sprintf("%s_dyn", cnameget(mtmp)[i]),\
                                  mtmp[,i])
    endloop

    # OLS regression of levels + deterministics
    list xlist_deter = xlist det_levels
    smpl (self.t1 + 1) ;
    series lrun_innovations = get_longrun_innovations(ys, xlist_deter)

    # Construct errors of dynamics: Has (T-1) observations due to differencing
    # Note: ols command not applicable as sdx can have multiple columns
    smpl full
    matrix self.srun_innovations = get_shortrun_innovations(xlist, det_dynamics)

    smpl (self.t1 + 1) ;
    matrix xdx = {xlist_deter}'self.srun_innovations

    # Concatenate errors
    matrix innovations = {lrun_innovations} ~ self.srun_innovations
    vcv_innovations = innovations'innovations

    if self.do_prewhite             # Pre-white residuals using VAR(p)
        matrix innovations_white
        matrix coeff_white = est_var_model(innovations, self.prewhitening_lag,\
                                           &innovations_white)
    else
        matrix innovations_white = innovations
    endif
    scalar self.Teffective = rows(innovations_white)

    if self.bandwidth == -1
        scalar self.bandwidth_value = compute_bandwidth(innovations_white,\
                                                         self.type_kernel)
    endif

    # Estimate covariances
    matrix kernel_est = compute_kernel(self.Teffective, self.type_kernel,\
                                       self.bandwidth_value)
    matrix sigma = innovations_white'innovations_white

    # long-run covariance matrix
    matrix lambda = longrun_cov(kernel_est, innovations_white)
    # TODO: Could longrun_cov be replaced by?
    /* Does not lead the same results!
    set hac_prewhiten on
    set hac_lag nw1 #self.prewhitening_lag
    set hac_kernel qs
    matrix my_lambda = lrcovar(innovations_white, FALSE)
    */

    matrix self.delta = sigma + lambda
    matrix self.omega = self.delta + lambda'

    if self.do_prewhite
        matrix ai
        matrix self.omega = recolor_omega(self.omega, coeff_white, &ai)
        matrix self.delta = recolor_delta(self.delta, coeff_white, ai,\
                                          vcv_innovations)
    endif

    bundle model = fmols_est(ys, xlist_deter, self)
    model.T = self.T
    model.name_endogenous = argname(ys)
    model.names_xlist = varnames(xlist)

    if self.verbose
        print_results(self, model)
    endif

    return model
end function


function bundle fmols_est (const series ys,
                           const list xlist_deter,
                           const bundle self)
    /* Actual FMOLS estimator. */

    smpl (1 + self.t1) ;

    bundle B
    scalar n_yxlist = self.cols_mymx
    scalar n_xlist = self.cols_mx

    g = mols(self.omega[2:n_yxlist, 1], self.omega[2:n_yxlist, 2:n_yxlist])

    delta_g = self.delta[2:n_yxlist, 1] - self.delta[2:n_yxlist, 2:n_yxlist] * g
    scalar k = get_trend_powermax(self.type_deterministic)
    delta_g |= zeros((k + 1), 1)    # this is "M*"

    # Clean "y"
    series mask = 1
    smpl full
    matrix B.ystar = ys - self.srun_innovations * g
    smpl mask == 1 --restrict

    # Cointegrating vector based on clean "y"
    matrix m_xlist_deter = {xlist_deter}
    matrix xxi = invpd(m_xlist_deter'm_xlist_deter)

    matrix bhat = xxi * (m_xlist_deter'B.ystar - delta_g)
    matrix B.bhat_coint = bhat[1:n_xlist]
    matrix B.bhat_deter = bhat[(n_xlist + 1):]

    #  Covariance matrix
    matrix sg = (self.omega[1,1] - self.omega[1,2:n_yxlist] * g) / $nobs
    matrix B.vcv = xxi * sg

    matrix se = sqrt(diag(B.vcv))
    matrix B.se_coint = se[1:n_xlist]
    matrix B.se_deter = se[(n_xlist + 1):]

    matrix B.ec = B.ystar - {xlist_deter} * bhat  # error-correction term

    return B
end function


function matrix recolor_delta (const matrix delta,
                               const matrix coeff_white "pre-whitened coeffs.",
                               const matrix ai,
                               const matrix vcv_innovations)
    /*  */
    return ai'delta * ai - ai'(coeff_white'vcv_innovations)
end function


function matrix recolor_omega (const matrix omega,
                               const matrix coeff_white "pre-whitened coeffs.",
                               matrix *ai)
    /*  */

    ai = inv( I(cols(omega)) - coeff_white)
    return qform(ai', omega)
end function


function matrix longrun_cov (const matrix kernel_est "weights",
                             const matrix u "innovations")
    /* Compute the long-run covariance matrix. */

    scalar T = rows(u)
    matrix lambda = mshape(0, cols(u), cols(u))

    loop j=1..rows(kernel_est)
        matrix m = u[1:(T-j),]'u[(1+j):T,]
        lambda += m * kernel_est[j]
    endloop

    return lambda
end function
